---
layout: page
permalink: /talks/
title: talks/teaching
description: 
years: [2021, 2020]
nav: true
---

<div class="publications">
<h1 id="teaching">teaching</h1>

<h3>80516/80816 Causality and Machine Learning</h3>
<p>In the past decades, interesting advances were made in machine learning, philosophy, and statistics for tackling 
long-standing causality problems, including how to discover causal knowledge from observational data, known as 
causal discovery, and how to infer the effect of interventions. Furthermore, it has recently been shown that the 
causal perspective may facilitate understanding and solving various machine learning / artificial intelligence problems such as transfer learning, semi-supervised learning, out-of-distribution prediction, disentanglement, and adversarial vulnerability. This course is accordingly concerned with understanding causality, learning causality from observational data, and using causality to tackle a large class of learning problems.<br>
The course covers probability theory, representations and usage of causal models, how causality is different from and connected to association, recent machine learning methods for causal discovery, and why and how the causal perspective helps in a class of learning tasks. We will try to answer the following questions. Why do we care about causality? How can we learning causality from observational data? What role does causality play in machine learning under data heterogeneity? Is causality an essential component in general-purpose artificial intelligence? If it is, how? What can we benefit from a philosophical, causal view of “intelligence”? How can deep learning benefit from a causal view?<br>
We will particularly focus on two key causality problems. One is causal discovery. It is well known that “correlation does not imply causality,” but we will make this statement more precise by asking what assumptions, what information in the data, and what procedures enable us to successfully recover causal information. Causal relations may happen between the underlying hidden variables, and what we measure may just be their reflections; so we will also see how to find hidden causal representations—the underlying hidden “causal” variables as well as their causal relations—by analyzing measured variables. Its implication in unsupervised deep learning will be discussed. The other is how to properly make use of causal information. This includes identification of causal effects, counterfactual reasoning, and improving machine learning in light of causal knowledge.
</p>

[//]: # (<h3>Introduction to Machine Learning</h3>)

[//]: # (<a href="https://www.cs.cmu.edu/~epxing/Class/10701-20/">[Course Website]</a>)

[//]: # (<p>Machine Learning is concerned with computer programs that automatically improve their performance through experience &#40;e.g., programs that learn to recognize human faces, recommend music and movies, and drive autonomous robots&#41;. This course covers the theory and practical algorithms for machine learning from a variety of perspectives. We cover topics such as Linear Regression, SVMs, Neural Networks, Graphical Models, Clustering, etc. Programming assignments include hands-on experiments with various learning algorithms. This course is designed to give a PhD-level student a thorough grounding in the methodologies, technologies, mathematics and algorithms currently needed by people who do research in machine learning.</p>)




<h1 id="talks">talks</h1>
{% bibliography -f talks %}


</div>
